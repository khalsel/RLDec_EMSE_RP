{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Extracting Microservices from Monolithic Systems using Deep Reinforcement Learning"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "This notebook includes all the code used to create the figures and the analysis of the evaluation section in the paper \"Extracting Microservices from Monolithic Systems using Deep Reinforcement Learning\" which has been submitted to the Empirical Software Engineering journal."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import itertools\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.lines import Line2D\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.stats import rankdata"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sns.set_theme()\n",
    "project_dir = os.curdir\n",
    "fig_path = os.path.join(project_dir,\"figures\")\n",
    "os.makedirs(fig_path, exist_ok=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# RQ1:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load and prepare data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# setup the variables\n",
    "logs_path = os.path.join(project_dir, \"data\", \"mono\")\n",
    "ascending_metrics = ['icp', 'ifn', 'ned']\n",
    "descending_metrics = ['chm', 'chd', 'smq', 'cmq', 'cov', \"msn\"]\n",
    "order_metric = \"chm\"\n",
    "groupby = [\"application\", \"configuration\"]\n",
    "groupby_data = dict()\n",
    "groupby_data[\"application\"] = ['plants', 'petclinic-legacy', 'acmeair', 'daytrader', 'roller']\n",
    "groupby_data[\"configuration\"] = ['Sequential', 'Flattened', 'CombSequential']\n",
    "metrics = [\"chm\", \"chd\", \"icp\", \"ned\", \"cov\"]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# load the data for all applications\n",
    "dfs = list()\n",
    "a = \"rldec\"\n",
    "for app in groupby_data[\"application\"]:\n",
    "    df = pd.read_csv(os.path.join(logs_path, a, app, \"results.csv\"), index_col=0)\n",
    "    df[\"application\"] = app\n",
    "    df[\"configuration\"] = df.apply(lambda x: re.fullmatch(r\"(\\S*)DQN\\d*/.*\", x[\"exp_id\"])[1], axis=1)\n",
    "    dfs.append(df)\n",
    "df = pd.concat(dfs, axis=0, ignore_index=True)\n",
    "df[\"approach\"] = a"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "metrics = [\"chm\", \"chd\", \"icp\"]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# find the decomposition that achieved the highest \"order_metric\" (default \"chm\") for each configuration and application\n",
    "keys = list(groupby_data.keys())\n",
    "if order_metric in descending_metrics:\n",
    "    df_m = df.groupby(keys)[order_metric].max().reset_index()\n",
    "else:\n",
    "    df_m = df.groupby(keys)[order_metric].min().reset_index()\n",
    "dff = df[df[keys+[order_metric]].apply(lambda x: np.all([np.any(x[i]==df_m[i]) for i in keys+[order_metric]]), axis=1)]\n",
    "df = dff.groupby(keys).first().reset_index()\n",
    "df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Generate boxplots"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# generate the barplot in a single figure (change save from None to a figure name to save the image)\n",
    "save = \"fig_rq1_barplots\"\n",
    "sns.set_theme()\n",
    "fig, axes = plt.subplots(1, len(metrics), figsize=(40,5))\n",
    "for i, m in enumerate(metrics):\n",
    "    g = sns.barplot(\n",
    "        data=df,\n",
    "        x=\"application\", y=m, hue=\"configuration\",\n",
    "        order=groupby_data[\"application\"], hue_order=groupby_data[\"configuration\"],\n",
    "        ax = axes[i], alpha=0.8\n",
    "    )\n",
    "    g.grid(False)\n",
    "    g.set_xlabel(\"\")\n",
    "    g.set_ylabel(m.upper(), rotation=90, size='large')\n",
    "    g.legend().set_title(\"\")\n",
    "plt.title(\"\")\n",
    "if save is not None:\n",
    "    plt.savefig(os.path.join(fig_path, \"{}.pdf\".format(save)),bbox_inches='tight')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# generate the barplot individually (change save from None to a figure name to save the images)\n",
    "sns.set_theme()\n",
    "for i, m in enumerate(metrics):\n",
    "    fig, axes = plt.subplots(1, 1, figsize=(12,5))\n",
    "    save = None #f\"fig_rq1_barplots_{m}\"\n",
    "    g = sns.barplot(\n",
    "        data=df,\n",
    "        x=\"application\", y=m, hue=\"configuration\",\n",
    "        order=groupby_data[\"application\"], hue_order=groupby_data[\"configuration\"],\n",
    "        alpha=0.8\n",
    "    )\n",
    "    g.grid(False)\n",
    "    g.set_xlabel(\"\")\n",
    "    g.set_ylabel(m.upper(), rotation=90, size='large')\n",
    "    g.legend().set_title(\"\")\n",
    "    plt.title(\"\")\n",
    "    if save is not None:\n",
    "        plt.savefig(os.path.join(fig_path, \"{}.pdf\".format(save)),bbox_inches='tight')\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# RQ2"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load and prepare data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# setup the variables\n",
    "logs_path = os.path.join(project_dir, \"data\", \"mono\")\n",
    "ascending_metrics = ['icp', 'ifn', 'ned', 'bcp']\n",
    "descending_metrics = ['chm', 'chd', 'smq', 'cmq', 'cov', \"msn\", \"score\"]\n",
    "order_metric = \"chm\"\n",
    "baselines = ['rldec', 'cogcn', 'topicdecomp', 'hydec', 'mono2micro', 'msextractor', 'random', 'boulder', 'grains']\n",
    "projects = ['plants', 'petclinic-legacy', 'acmeair', 'daytrader', 'roller', 'jpetstore-6', 'partsunlimitedmrp', '7ep-demo']\n",
    "groupby = [\"application\",\"approach\"]\n",
    "ned_threshold = 0.85\n",
    "groupby_data = {\"application\":projects, \"approach\":baselines}\n",
    "metrics = [\"chm\", \"chd\", \"icp\", \"ned\", \"bcp\", \"cov\", \"msn\"]\n",
    "save = None #\"rq2_boxplots\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# load the data\n",
    "dfs = list()\n",
    "for a in os.listdir(logs_path):\n",
    "    df_list = list()\n",
    "    for app in os.listdir(os.path.join(logs_path, a)):\n",
    "        df = pd.read_csv(os.path.join(logs_path, a, app, \"results.csv\"), index_col=0)\n",
    "        if a==\"rldec\":\n",
    "            df = df[df.apply(lambda x: x[\"exp_id\"].startswith(\"CombSequential\"), axis=1)] # use only the CombSequential configuration\n",
    "        df[\"application\"] = app\n",
    "        df_list.append(df)\n",
    "    df = pd.concat(df_list, axis=0, ignore_index=True)\n",
    "    if a==\"benchmark\":\n",
    "        df[\"approach\"] = df.apply(lambda x: \"other_random\" if x[\"exp_id\"].startswith(\"random_\") else x[\"exp_id\"], axis=1)\n",
    "    else:\n",
    "        df[\"approach\"] = a\n",
    "        df = df[df.ned<=ned_threshold] # We exclude decompositions whose NED values exceed the threshold (extreme/outlier decompositions)\n",
    "    dfs.append(df)\n",
    "df = pd.concat(dfs, axis=0, ignore_index=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# train the standard scaler and add the combined metric DSCORE\n",
    "dfcp = df.copy()\n",
    "df[\"score\"] = 0\n",
    "for app in df.application.unique():\n",
    "    cond = (df.application==app)\n",
    "    for m in metrics:\n",
    "        if m in [\"cov\", \"msn\"]:\n",
    "            continue\n",
    "        x = StandardScaler().fit_transform(df[cond][m].values.reshape(-1, 1))[:,0]\n",
    "        if m in descending_metrics:\n",
    "            df.loc[cond, \"score\"] += x\n",
    "            dfcp.loc[cond, m] = x\n",
    "        else:\n",
    "            x = StandardScaler().fit_transform(df[cond][m].values.reshape(-1, 1))[:,0]\n",
    "            df.loc[cond, \"score\"] -= x\n",
    "            dfcp.loc[cond, m] = x\n",
    "metrics.append(\"score\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Select decompositions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# find the decomposition that achieved the highest \"order_metric\" (default \"chm\") for each configuration and application\n",
    "keys = list(groupby_data.keys()) # application/approach\n",
    "selection_metric = \"score\"\n",
    "if selection_metric in descending_metrics:\n",
    "    df_m = df.groupby(keys)[selection_metric].max().reset_index()\n",
    "else:\n",
    "    df_m = df.groupby(keys)[selection_metric].min().reset_index()\n",
    "dff = df[np.any([(df[keys+[selection_metric]]==df_m.iloc[i]).all(1) for i in range(df_m.shape[0])], axis=0)]\n",
    "df_b = dff.groupby(keys).first().reset_index()\n",
    "assert df_b.shape[0]==df_m.shape[0]\n",
    "df_b.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# We find the median and best (decomposition that maximised the selection metric) decompositions for each application/approach\n",
    "df_bb = df_b.set_index([\"application\", \"approach\"])\n",
    "m1 = pd.MultiIndex.from_product([projects, baselines])\n",
    "m2 = pd.MultiIndex.from_product([metrics, [\"median\", \"best\"]])\n",
    "df_tab = pd.DataFrame(index=m2, columns = m1)\n",
    "for i, project in enumerate(projects):\n",
    "    for j, baseline in enumerate(baselines):\n",
    "        dft = df[(df[\"application\"]==project)&(df[\"approach\"]==baseline)]\n",
    "        for metric in metrics:\n",
    "            df_tab.loc[(metric, \"median\"), (project, baseline)] = round(dft[metric].median(), 3)\n",
    "            df_tab.loc[(metric, \"best\"), (project, baseline)] = round(df_bb.loc[(project, baseline)][metric], 3)\n",
    "df_tab"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Prepare RQ2 tables"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Ensure the decompositions \"boulder\", \"random\", \"grains\" are never included in the selection process\n",
    "df_tab_copy = df_tab.copy()\n",
    "for m in metrics:\n",
    "    if m in descending_metrics:\n",
    "        val = df_tab_copy.loc[(m,\"median\")].min()\n",
    "    else:\n",
    "        val = df_tab_copy.loc[(m,\"median\")].max()\n",
    "    for a in [\"boulder\", \"random\", \"grains\"]:\n",
    "        for v in [\"median\", \"best\"]:\n",
    "            for app in projects:\n",
    "                df_tab_copy.loc[(m,v), (app,a)] = val\n",
    "# find the best baseline for each application/metric\n",
    "df_tab_is_max = df_tab.T.copy()\n",
    "for c in df_tab_is_max.columns:\n",
    "    df_tab_is_max[c] = False\n",
    "for app in projects:\n",
    "    for m in metrics:\n",
    "        if m in [\"msn\", \"cov\"]:\n",
    "            continue\n",
    "        func = np.argmax if m in descending_metrics else np.argmin\n",
    "        for v in [\"median\", \"best\"]:\n",
    "            a = df_tab_copy.T.loc[app].index.values[func(df_tab_copy.T.loc[app][(m,v)])]\n",
    "            df_tab_is_max.loc[(app, a), (m,v)] = True\n",
    "# Highlight in bold the best value for each application/metric in the table\n",
    "def custom_format(x):\n",
    "    return f\"\\\\textbf{{{x[0]:0.3f}}}\" if df_tab_is_max.loc[x.index[0], x.name] else f\"{x[0]:0.3f}\"\n",
    "df_cp = df_tab.apply(lambda x: pd.DataFrame(x).apply(custom_format, axis=1))\n",
    "df_cp"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "metric_name_map = {\n",
    "    \"chm\": r\"CHM $\\nearrow$\",\n",
    "    \"chd\": r\"CHD $\\nearrow$\",\n",
    "    \"icp\": r\"ICP $\\searrow$\",\n",
    "    \"bcp\": r\"BCP $\\searrow$\",\n",
    "    \"ned\": r\"NED $\\searrow$\",\n",
    "    \"cov\": r\"COV $\\nearrow$\",\n",
    "    \"msn\": r\"MSN\",\n",
    "    \"score\": r\"SCORE $\\nearrow$\",\n",
    "}\n",
    "app_name_map = {\n",
    "    \"plants\": \"Plants\",\n",
    "    \"petclinic-legacy\": \"PetClinic\",\n",
    "    \"acmeair\": \"ACMEair\",\n",
    "    \"daytrader\": \"DayTrader\",\n",
    "    \"roller\": \"Roller\",\n",
    "    \"jpetstore-6\": \"JPetStore\",\n",
    "    \"7ep-demo\": \"7ep-demo\",\n",
    "    \"partsunlimitedmrp\": \"PartsMRP\"\n",
    "}\n",
    "baseline_name_map = {\n",
    "    \"rldec\": \"RLDec\",\n",
    "    \"cogcn\": \"CoGCN\",\n",
    "    \"topicdecomp\": \"TopicDecomp\",\n",
    "    \"hydec\": \"HyDec\",\n",
    "    \"mono2micro\": \"Mono2micro\",\n",
    "    \"msextractor\": \"MSExtractor\",\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dft = df_cp.T.reset_index().rename(columns={\"level_0\":\"application\", \"level_1\":\"baseline\"})\n",
    "step = 2\n",
    "metrics_to_use = ['chm', 'chd', 'icp', 'bcp', 'ned', 'cov', 'score']\n",
    "for i in range(0, len(projects), step):\n",
    "    app = projects[i]\n",
    "    app2 = projects[i+1]\n",
    "    dfts = dict()\n",
    "    for a in [app, app2]:\n",
    "        dftt = dft[dft.application==a]\n",
    "        name = app_name_map[a] if a in app_name_map else a\n",
    "        dftt[\"baseline\"] = dftt[\"baseline\"].apply(lambda b: baseline_name_map[b] if b in baseline_name_map else b)\n",
    "        dftt = dftt.drop(columns=[\"application\"]).set_index(\"baseline\")\n",
    "        dftt = dftt[[(m,\"best\") for m in metrics_to_use]]\n",
    "        dftt.columns = [metric_name_map[m] if m in metric_name_map else m for m in  metrics_to_use]\n",
    "        dfts[name] = dftt\n",
    "    dff = pd.concat(dfts, axis=1)\n",
    "    display(dff)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Create rankings table"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# sort the baselines for each application/metric\n",
    "dff = pd.DataFrame(index=df_tab.T.index)\n",
    "for m in metrics:\n",
    "    dff[m] = df_tab.T[(m, \"best\")]\n",
    "dff = dff.reset_index().rename(columns={\"level_0\":\"application\", \"level_1\":\"approach\"})\n",
    "to_show = ['rldec', 'cogcn', 'topicdecomp', 'hydec', 'mono2micro', 'msextractor']\n",
    "metrics_to_use = [\"chm\", \"chd\", \"icp\", \"bcp\", \"ned\", \"score\"]\n",
    "df_pos = dff[dff.approach.isin(to_show)].copy().set_index([\"application\",\"approach\"])[metrics_to_use]\n",
    "for app in df_pos.reset_index().application.unique():\n",
    "    for m in df_pos.columns:\n",
    "        if m in descending_metrics:\n",
    "            ascending = False\n",
    "        else:\n",
    "            ascending = True\n",
    "        dft = dff[[\"application\",\"approach\", m]]\n",
    "        dft = dft[dft.application==app][[\"approach\", m]]\n",
    "        dft = dft[dft.approach.isin(to_show)]\n",
    "        df_pos.loc[zip(itertools.repeat(app), dft.approach), m] = rankdata(dft[m].values*(2*ascending-1))\n",
    "df_pos = df_pos.astype(np.int64)\n",
    "df_pos"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Calculate the sum of rankings over the applications\n",
    "df_spos = df_pos.reset_index().groupby(\"approach\").sum()\n",
    "df_spos"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Format the table for the LaTeX paper\n",
    "rankings = df_spos.apply(lambda x: rankdata(x).astype(int), axis=0)\n",
    "def custom_format(x):\n",
    "    if rankings.loc[x.name, x.index[0]]==1:\n",
    "        t = f\"\\\\textbf{{{x[0]}}}\"\n",
    "    elif rankings.loc[x.name, x.index[0]]==2:\n",
    "        t = f\"{x[0]}*\"\n",
    "    elif rankings.loc[x.name, x.index[0]]==3:\n",
    "        t = f\"\\\\textit{{{x[0]}}}\"\n",
    "    else:\n",
    "        t = f\"{x[0]}\"\n",
    "    return t\n",
    "df_spos_cp = df_spos.apply(lambda x: pd.DataFrame(x).apply(custom_format, axis=1))\n",
    "df_spos_cp"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def custom_format(x):\n",
    "    if rankings.loc[x.name, x.index[0]]==1:\n",
    "        t = f\"\\\\textbf{{{x[0]}}}\"\n",
    "    elif rankings.loc[x.name, x.index[0]]==2:\n",
    "        t = f\"{x[0]}*\"\n",
    "    elif rankings.loc[x.name, x.index[0]]==3:\n",
    "        t = f\"\\\\textit{{{x[0]}}}\"\n",
    "    else:\n",
    "        t = f\"{x[0]}\"\n",
    "    return t\n",
    "df_spos_cp = df_spos.apply(lambda x: pd.DataFrame(x).apply(custom_format, axis=1))\n",
    "df_spos_cp"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# RQ3:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Empirical evaluation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Load and prepare data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# setup the variables\n",
    "ned_threshold = 0.85\n",
    "micro_logs_path = os.path.join(project_dir, \"data\", \"micro\")\n",
    "acc_metrics = ['accuracy', 'precision.1', 'recall.1', 'f1_score', 'roc_auc', 'fbeta_score']\n",
    "to_include = ['chm', 'chd', 'smq', 'cmq', 'icp', 'msn', 'ned', \"precision\", \"recall\", \"SRP@5\", \"SRP@7\", \"SRP@9\"] + acc_metrics\n",
    "metrics = ['chm', 'chd', 'icp', 'ned', 'msn', \"precision\", \"recall\", \"SRP@5\", \"SRP@9\", 'precision.1', 'recall.1', 'fbeta_score']\n",
    "ascending_metrics = ['icp', 'ifn', 'ned']\n",
    "descending_metrics = ['score', 'chm', 'chd', 'smq', 'cmq', 'cov', \"msn\", \"precision\", \"recall\"] + [\"SRP@\"+str(i) for i in range(11)] + [\"SRR@\"+str(i) for i in range(11)] + acc_metrics\n",
    "order_metric = \"fbeta_score\"\n",
    "baselines = ['rldec', 'benchmark']\n",
    "projects = ['petclinic-microservices', 'es-kanban-board', 'microservices-event-sourcing', 'social-edition-modular', 'social-edition-microservices']\n",
    "rename = ['petclinic', 'kanban', 'event-sourcing', 'social-modular', 'social-microservices']\n",
    "rename_map = {i:j for i,j in zip(projects, rename)}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# load the RLDec data\n",
    "dfs = list()\n",
    "a = \"rldec\"\n",
    "for app in os.listdir(os.path.join(micro_logs_path, a)):\n",
    "    df = pd.read_csv(os.path.join(micro_logs_path, a, app, \"results.csv\"), index_col=0)\n",
    "    df[\"application\"] = app\n",
    "    dfs.append(df)\n",
    "    old_columns = df.columns\n",
    "df = pd.concat(dfs, axis=0, ignore_index=True)\n",
    "df[\"approach\"] = a\n",
    "df = df[[\"application\", \"approach\"]+to_include]\n",
    "df[\"application_short\"] = df.apply(lambda x: rename_map[x[\"application\"]], axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# load the benchmark data\n",
    "dfs = list()\n",
    "a = \"benchmark\"\n",
    "for app in os.listdir(os.path.join(micro_logs_path, a)):\n",
    "    df2 = pd.read_csv(os.path.join(micro_logs_path, a, app, \"results.csv\"), index_col=0)\n",
    "    df2[\"application\"] = app\n",
    "    df2.columns = old_columns\n",
    "    dfs.append(df2)\n",
    "df2 = pd.concat(dfs, axis=0, ignore_index=True)\n",
    "df2[\"approach\"] = df2.apply(lambda x: \"other_random\" if x[\"exp_id\"].startswith(\"random_\") else x[\"exp_id\"], axis=1)\n",
    "df2 = df2[[\"application\", \"approach\"]+to_include]\n",
    "df2[\"application_short\"] = df2.apply(lambda x: rename_map[x[\"application\"]], axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Exclude outliers and concat data\n",
    "df = df[(df.ned<ned_threshold)|(df.approach!=\"rldec\")]\n",
    "df3 = pd.concat([df, df2])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Boxplots"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### MSFB boxplot"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "save = \"fig_rq3_boxplots_fbeta\"\n",
    "baselines = ['rldec']\n",
    "\n",
    "metric = \"fbeta_score\"\n",
    "metric_rename = \"MSFB\"\n",
    "fig, axes = plt.subplots(1, 1, figsize=(10,5))\n",
    "dft = df.rename(columns={metric:metric_rename})\n",
    "x = sns.boxplot(data=dft, x=\"application_short\", y=metric_rename, ax = axes, order=rename)\n",
    "extra_legend_elements = [\n",
    "    Line2D([0], [0], color=\"brown\", label=\"random\", ls=\"--\"),\n",
    "    Line2D([0], [0], color=\"darkolivegreen\", label=\"boulder\", ls=\"-.\"),\n",
    "]\n",
    "for i, app in enumerate(rename):\n",
    "    for v, c, ls in zip([\"random\", \"boulder\"], [\"brown\", \"darkolivegreen\"], [\"--\", \"-.\"]): #[\"red\", \"green\"]\n",
    "        y = df2[(df2.application_short==app)&(df2.approach==v)].iloc[0][metric]\n",
    "        x.axhline(y = y,\n",
    "                   xmin = 0.02 + i*0.2,\n",
    "                   xmax = 0.18 + i*0.2,\n",
    "                  color=c, linestyle=ls, linewidth=2)\n",
    "x.grid(False)\n",
    "x.get_xaxis().get_label().set_visible(False)\n",
    "axes.legend(handles=extra_legend_elements, loc=\"upper right\")\n",
    "plt.title(\"\")\n",
    "if save is not None:\n",
    "    plt.savefig(os.path.join(fig_path, \"{}.pdf\".format(save)), bbox_inches='tight')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### MSE-precision and MSE-recall boxplots"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "save = \"fig_rq3_boxplots_mse\"\n",
    "baselines = ['rldec']\n",
    "\n",
    "metrics = [\"precision\", \"recall\"]\n",
    "new_metric_names = [\"mse-precision\", \"mse-recall\"]\n",
    "dft = df.rename(columns={m:nm for m, nm in zip(metrics, new_metric_names)})\n",
    "fig, axes = plt.subplots(1, len(metrics), figsize=(20,5))\n",
    "for j,m in enumerate(new_metric_names):\n",
    "    x = sns.boxplot(data=dft, x=\"application_short\", y=m, ax = axes[j], order=rename)\n",
    "    x.grid(False)\n",
    "    x.get_xaxis().get_label().set_visible(False)\n",
    "plt.title(\"\")\n",
    "if save is not None:\n",
    "    plt.savefig(os.path.join(fig_path, \"{}.pdf\".format(save)), bbox_inches='tight')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### SRP boxplots"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "save = \"fig_rq3_boxplots_srp\"\n",
    "metrics = [\"SRP@5\", \"SRP@9\"]\n",
    "fig, axes = plt.subplots(1, len(metrics), figsize=(20,5))\n",
    "for j,m in enumerate(metrics):\n",
    "    x = sns.boxplot(data=df, x=\"application_short\", y=m, ax = axes[j], order=rename)\n",
    "    x.grid(False)\n",
    "    x.get_xaxis().get_label().set_visible(False)\n",
    "plt.title(\"\")\n",
    "if save is not None:\n",
    "    plt.savefig(os.path.join(fig_path, \"{}.pdf\".format(save)), bbox_inches='tight')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Qualitative example"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "app = \"petclinic-microservices\"\n",
    "micro_logs_path = os.path.join(os.curdir, \"data\", \"micro\")\n",
    "to_include = ['chm', 'chd', 'smq', 'cmq', 'icp', 'ned', \"precision\", \"recall\", \"SRP@5\", \"SRP@7\", \"SRP@9\"]\n",
    "ascending_metrics = ['icp', 'ifn', 'ned']\n",
    "descending_metrics = ['chm', 'chd', 'smq', 'cmq', 'cov', \"msn\", \"precision\", \"recall\"] + [\"SRP@\"+str(i) for i in range(11)] + [\"SRR@\"+str(i) for i in range(11)]\n",
    "ned_threshold = 0.85"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# load the data\n",
    "a = \"rldec\"\n",
    "df = pd.read_csv(os.path.join(micro_logs_path, a, app, \"results.csv\"), index_col=0) # Load the decomposition metric data\n",
    "decomps = pd.read_csv(os.path.join(micro_logs_path, a, app, \"decompositions.csv\"), index_col=0) # Load the decompositions\n",
    "cond = df.ned<ned_threshold\n",
    "df = df[cond]\n",
    "decomps = decomps[cond]\n",
    "df[\"application\"] = app\n",
    "df[\"approach\"] = a\n",
    "# df[\"f1score\"] = df.apply(lambda x: f1score(x[\"precision\"], x[\"recall\"]), axis=1)\n",
    "order_metric = \"fbeta_score\"\n",
    "top_decomp_index = np.argmax(df[order_metric])\n",
    "top_decomp_metrics = df.iloc[top_decomp_index]\n",
    "top_decomp = decomps.iloc[top_decomp_index]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# load the data\n",
    "a = \"topicdecomp\"\n",
    "df = pd.read_csv(os.path.join(micro_logs_path, a, app, \"results.csv\"), index_col=0) # Load the decomposition metric data\n",
    "decomps = pd.read_csv(os.path.join(micro_logs_path, a, app, \"decompositions.csv\"), index_col=0) # Load the decompositions\n",
    "cond = df.ned<ned_threshold\n",
    "df = df[cond]\n",
    "decomps = decomps[cond]\n",
    "df[\"application\"] = app\n",
    "df[\"approach\"] = a\n",
    "# df[\"f1score\"] = df.apply(lambda x: f1score(x[\"precision\"], x[\"recall\"]), axis=1)\n",
    "order_metric = \"fbeta_score\"\n",
    "top_decomp_td_index = np.argmax(df[order_metric])\n",
    "top_decomp_td_metrics = df.iloc[top_decomp_td_index]\n",
    "top_decomp_td = decomps.iloc[top_decomp_td_index]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "display(top_decomp_metrics)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "display(top_decomp_td_metrics)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "display(top_decomp)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Generate graph visualization of the actual microservices"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from pyvis.network import Network\n",
    "from matplotlib.colors import to_hex"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "shape = (800, 1500)\n",
    "output_path = os.path.join(os.curdir, \"figures\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class_names = list(top_decomp.index)\n",
    "node_map_s = {i:re.match(r\"spring-petclinic-([^.]*)\\..*\", i)[1] for i in class_names}\n",
    "short_names = {i:i.split(\".\")[-1] for i in class_names}\n",
    "nodes = list(node_map_s.keys()) # classes\n",
    "services_s = list(set(node_map_s.values()))  # microservices"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "colors_s = dict()\n",
    "for i, service in enumerate(services_s):\n",
    "    colors_s[service] = to_hex(plt.cm.Pastel1.colors[i])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "N = Network(shape[0], shape[1], directed=False, notebook=False)\n",
    "N.force_atlas_2based()\n",
    "for n in nodes:\n",
    "    N.add_node(n, label=short_names[n], title=n, color=colors_s[node_map_s[n]])\n",
    "for service in services_s:\n",
    "    N.add_node(service, label=service, title=service, color=colors_s[service], shape='box')\n",
    "for c, s in node_map_s.items():\n",
    "    N.add_edge(c, s)\n",
    "N.show(os.path.join(output_path, \"{}_true_micro.html\".format(app)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Generate graph visualization of the RLDec microservices"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from pyvis.network import Network\n",
    "from matplotlib.colors import to_hex"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "shape = (800, 1500)\n",
    "output_path = os.path.join(os.curdir, \"figures\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class_names = list(top_decomp.index)\n",
    "node_map = {i: \"micro_{}\".format(v) for i, v in zip(top_decomp.index, top_decomp.values)}\n",
    "short_names = {i:i.split(\".\")[-1] for i in class_names}\n",
    "nodes = list(node_map.keys()) # classes\n",
    "services = list(set(node_map.values()))  # microservices"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "colors = dict()\n",
    "for i, service in enumerate(services):\n",
    "    colors[service] = to_hex(plt.cm.Pastel1.colors[(len(colors_s)+i)%len(plt.cm.Pastel1.colors)])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "svc_map = {svc:[colors_s[node_map_s[c]] for c in node_map if node_map[c]==svc] for svc in services}\n",
    "svc_map = {svc:pd.value_counts(svc_map[svc]).sort_values().index[-1] for svc in svc_map}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "N = Network(shape[0], shape[1], directed=False, notebook=False)\n",
    "N.force_atlas_2based()\n",
    "for n in nodes:\n",
    "    N.add_node(n, label=short_names[n], title=n, color=colors_s[node_map_s[n]])\n",
    "for service in services:\n",
    "    N.add_node(service, label=service, title=service, color=svc_map[service], shape='box')\n",
    "for service in services_s:\n",
    "    N.add_node(service, label=service, title=service, color=colors_s[service], shape='ellipsis')\n",
    "for c, s in node_map.items():\n",
    "    N.add_edge(c, s)\n",
    "N.show(os.path.join(output_path, \"{}_rldec_micro.html\".format(app)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Generate graph visualization of the generated microservices"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from pyvis.network import Network\n",
    "from matplotlib.colors import to_hex"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "shape = (800, 1500)\n",
    "output_path = os.path.join(os.curdir, \"figures\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class_names = list(top_decomp_td.index)\n",
    "node_map = {i: \"micro_{}\".format(v) for i, v in zip(top_decomp_td.index, top_decomp_td.values)}\n",
    "short_names = {i:i.split(\".\")[-1] for i in class_names}\n",
    "nodes = list(node_map.keys()) # classes\n",
    "services = list(set(node_map.values()))  # microservices"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "colors = dict()\n",
    "for i, service in enumerate(services):\n",
    "    colors[service] = to_hex(plt.cm.Pastel1.colors[(len(colors_s)+i)%len(plt.cm.Pastel1.colors)])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "svc_map = {svc:[colors_s[node_map_s[c]] for c in node_map if node_map[c]==svc] for svc in services}\n",
    "svc_map = {svc:pd.value_counts(svc_map[svc]).sort_values().index[-1] for svc in svc_map}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "N = Network(shape[0], shape[1], directed=False, notebook=False)\n",
    "N.force_atlas_2based()\n",
    "for n in nodes:\n",
    "    N.add_node(n, label=short_names[n], title=n, color=colors_s[node_map_s[n]])\n",
    "for service in services:\n",
    "    N.add_node(service, label=service, title=service, color=svc_map[service], shape='box')\n",
    "for service in services_s:\n",
    "    N.add_node(service, label=service, title=service, color=colors_s[service], shape='ellipsis')\n",
    "for c, s in node_map.items():\n",
    "    N.add_edge(c, s)\n",
    "N.show(os.path.join(output_path, \"{}_topicdecomp_micro.html\".format(app)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:decomp]",
   "language": "python",
   "name": "conda-env-decomp-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}